{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1824099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Camp\n",
    "#### Python Data Science Toolbox pt2\n",
    "\n",
    "Iterables, Iteratiors, List comprehensions, Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf2761",
   "metadata": {},
   "source": [
    "iterables - lists, string, range objects, dictionaries, file connections, others tha thave an iter() method \n",
    "- applying iter() to an iterable creates an iterator\n",
    "\n",
    "iterator - object with associated next() method that produces the consecutive values\n",
    "        #define iterator\n",
    "        word = 'Da'\n",
    "        #pass to function next()\n",
    "        it = iter(word)\n",
    "        #returns the first value\n",
    "        'D'\n",
    "        #calling next() again returns the next value\n",
    "        next(it)\n",
    "        'a'\n",
    "        #until there are no more values to return\n",
    "        'Stopiteration error'\n",
    "        \n",
    "        use * operator to unpack all values\n",
    "        word = 'Data'\n",
    "        it = iter(word)\n",
    "        print(*it)\n",
    "        D a t a\n",
    "        print(it)\n",
    "        error\n",
    "        \n",
    "        unpack dictionaries to iterate\n",
    "        pythonistas={'hugo':'b', 'francis':'c'}\n",
    "        for key, value in pythonistas.items():\n",
    "            print(key, value)\n",
    "            \n",
    "        file = open('file.txt')\n",
    "        it = iter(file)\n",
    "        print(next(it))\n",
    "        returns first line\n",
    "        \n",
    "        print(next(it))\n",
    "        returns second line\n",
    "\n",
    "Recap\n",
    "- an iterable is an object that can return an iterator, while an iterator is an object that keeps state and produces the next value when you call next() on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bcc90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of strings: flash\n",
    "flash = ['jay garrick', 'barry allen', 'wally west', 'bart allen']\n",
    "\n",
    "# Print each list item in flash using a for loop\n",
    "for person in flash:\n",
    "    print(person)\n",
    "\n",
    "# Create an iterator for flash: superhero\n",
    "superhero = iter(flash)\n",
    "\n",
    "# Print each item from the iterator\n",
    "print(next(superhero))\n",
    "print(next(superhero))\n",
    "print(next(superhero))\n",
    "print(next(superhero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d45e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an iterator for range(3): small_value\n",
    "small_value = iter(range(3))\n",
    "\n",
    "# Print the values in small_value\n",
    "print(next(small_value))\n",
    "print(next(small_value))\n",
    "print(next(small_value))\n",
    "\n",
    "# Loop over range(3) and print the values\n",
    "for num in range(3):\n",
    "    print(num)\n",
    "\n",
    "\n",
    "# Create an iterator for range(10 ** 100): googol\n",
    "googol = iter(range(10**100))\n",
    "\n",
    "# Print the first 5 values from googol\n",
    "print(next(googol))\n",
    "print(next(googol))\n",
    "print(next(googol))\n",
    "print(next(googol))\n",
    "print(next(googol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d09f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iterators as function arguments\n",
    "\n",
    "# Create a range object: values\n",
    "values = range(10,21)\n",
    "\n",
    "# Print the range object\n",
    "print(values)\n",
    "\n",
    "# Create a list of integers: values_list\n",
    "values_list = list(values)\n",
    "\n",
    "# Print values_list\n",
    "print(values_list)\n",
    "\n",
    "# Get the sum of values: values_sum\n",
    "values_sum = sum(values)\n",
    "\n",
    "# Print values_sum\n",
    "print(values_sum)\n",
    "\n",
    "OUTPUT: \n",
    "range(10, 21)\n",
    "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "165"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aa625d",
   "metadata": {},
   "source": [
    "#### Playing with iterators\n",
    "\n",
    "- enumerate() take in any iterable and returns an enumewrate object (pair containing original iterable and index within iterable)\n",
    "\n",
    "        avengers = ['hawkeye', 'iron man', 'thor', 'quicksilver']\n",
    "        e = enumerate(avengers)\n",
    "        e_list = list(e)\n",
    "        print(e_list)\n",
    "        [(0, 'hawkeye'), (1, 'iron man'), (2, 'thor'), (3, 'quicksilver')]\n",
    "\n",
    "- the enumerate object itself is an iterable and can be looped over to unpack with \n",
    "        for index, value in enumerate(avengers):\n",
    "            print(index, value)\n",
    "        #modify the start number from default of 0\n",
    "        for index, value in enumerate(avengers, start = 10)\n",
    "\n",
    "-zip accepts iterables and returns tuples zipped together\n",
    "        avengers =  ['hawkeye', 'iron man', 'thor', 'quicksilver']\n",
    "        names = ['barton', 'start', 'adinson', 'maximoff']\n",
    "        z = zip(avengers, names)\n",
    "        z_list = list(z)\n",
    "        print(z_list)\n",
    "        [('hawkeye', 'barton'), ('iron man', 'stark'), ('thor', 'odinson'), ('quicksilver', 'maximoff')]\n",
    "        \n",
    "        other options:\n",
    "        #for loop\n",
    "        for z1, z2 in zip(avengers, names):\n",
    "            print(z1, z2)\n",
    "        prints each line as a string\n",
    "        \n",
    "        #splat operator\n",
    "        z = zip(avengers, names)\n",
    "        print(*z)\n",
    "        prints a series of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using enumerate()\n",
    "\n",
    "# Create a list of strings: mutants\n",
    "mutants = ['charles xavier', \n",
    "            'bobby drake', \n",
    "            'kurt wagner', \n",
    "            'max eisenhardt', \n",
    "            'kitty pryde']\n",
    "\n",
    "# Create a list of tuples: mutant_list\n",
    "mutant_list = list(enumerate(mutants))\n",
    "\n",
    "# Print the list of tuples\n",
    "print(mutant_list)\n",
    "\n",
    "# Unpack and print the tuple pairs\n",
    "for index1, value1 in enumerate(mutants):\n",
    "    print(index1, value1)\n",
    "\n",
    "# Change the start index\n",
    "for index2, value2 in enumerate(mutants, start=1):\n",
    "    print(index2, value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5655b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using zip()\n",
    "\n",
    "# Create a list of tuples: mutant_data\n",
    "mutant_data = list(zip(mutants, aliases, powers))\n",
    "\n",
    "# Print the list of tuples\n",
    "print(mutant_data)\n",
    "\n",
    "# Create a zip object using the three lists: mutant_zip\n",
    "mutant_zip = zip(mutants, aliases, powers)\n",
    "\n",
    "# Print the zip object\n",
    "print(mutant_zip)\n",
    "\n",
    "# Unpack the zip object and print the tuple values\n",
    "for value1, value2, value3 in mutant_zip:\n",
    "    print(value1, value2, value3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using * and zip to 'unzip'\n",
    "\n",
    "# Create a zip object from mutants and powers: z1\n",
    "z1 = zip(mutants, powers)\n",
    "\n",
    "# Print the tuples in z1 by unpacking with *\n",
    "print(*z1)\n",
    "\n",
    "# Re-create a zip object from mutants and powers: z1\n",
    "z1 = zip(mutants, powers)\n",
    "\n",
    "# 'Unzip' the tuples in z1 by unpacking with * and zip(): result1, result2\n",
    "result1, result2 = zip(*z1)\n",
    "\n",
    "# Check if unpacked tuples are equivalent to original tuples\n",
    "print(result1 == mutants)\n",
    "print(result2 == powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a914624c",
   "metadata": {},
   "source": [
    "##### Using iterators to load large files into memory\n",
    "\n",
    "Loading data in chunks when there is too much data to hold in memory\n",
    "Pandas read_csv() allows this with the argument chunksize\n",
    "        import pandas as pd\n",
    "        result = []\n",
    "        for chunk in pd.read_csv('data.csv', chunksize=1000)\n",
    "            result.append(sum(chunk['x']))\n",
    "        total = sum(result)\n",
    "        print(total)\n",
    "        \n",
    "        #another method\n",
    "        total=0\n",
    "        for chunk in pd.read_csv('data.csv', chunksize = 1000)\n",
    "            total += sum(chunk['x'])\n",
    "            print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf6b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing large amounts of Twitter data\n",
    "\n",
    "# Initialize an empty dictionary: counts_dict\n",
    "counts_dict={}\n",
    "\n",
    "# Iterate over the file chunk by chunk\n",
    "for chunk in pd.read_csv('tweets.csv', chunksize=10):\n",
    "\n",
    "    # Iterate over the column in DataFrame\n",
    "    for entry in chunk['lang']:\n",
    "        if entry in counts_dict.keys():\n",
    "            counts_dict[entry] += 1\n",
    "        else:\n",
    "            counts_dict[entry] = 1\n",
    "\n",
    "# Print the populated dictionary\n",
    "print(counts_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb82be5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make code reusable by defining a function\n",
    "\n",
    "# Define count_entries()\n",
    "def count_entries(csv_file, c_size, colname):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "    \n",
    "    # Initialize an empty dictionary: counts_dict\n",
    "    counts_dict = {}\n",
    "\n",
    "    # Iterate over the file chunk by chunk\n",
    "    for chunk in pd.read_csv(csv_file, chunksize = c_size):\n",
    "\n",
    "        # Iterate over the column in DataFrame\n",
    "        for entry in chunk[colname]:\n",
    "            if entry in counts_dict.keys():\n",
    "                counts_dict[entry] += 1\n",
    "            else:\n",
    "                counts_dict[entry] = 1\n",
    "\n",
    "    # Return counts_dict\n",
    "    return counts_dict\n",
    "\n",
    "# Call count_entries(): result_counts\n",
    "result_counts = count_entries('tweets.csv', c_size=10, colname='lang')\n",
    "\n",
    "# Print result_counts\n",
    "print(result_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5145db",
   "metadata": {},
   "source": [
    "## CHAPTER 2 - List Comprehensions\n",
    "\n",
    "Create lists from other lists or from dataframe columns\n",
    "\n",
    "        #computationally expensive\n",
    "        nums = [12, 8, 21, 3, 16]\n",
    "        new_nums = []\n",
    "        for num in nums:\n",
    "            new_nums.append(num + 1)\n",
    "\n",
    "        #list comprehension\n",
    "        nums = [12, 8, 21, 3, 16]\n",
    "        new_nums = [nums + 1 for num in nums]\n",
    "        \n",
    "- can write list comprehension over any iterable\n",
    "    \n",
    "        result = [num for num in range(11)]\n",
    "        print(result)\n",
    "\n",
    "- list comprehension requires:\n",
    "    - iterable\n",
    "    - iterator variable (represent member of iterable)\n",
    "    - output expression\n",
    "    \n",
    "    \n",
    "- can replace nested loop\n",
    "        #computationally expensive\n",
    "        pairs_1 = []\n",
    "        for num1 in range(0,2):\n",
    "            for num2 in range(6,8)\"\n",
    "                pairs_1.append(num1, num2)\n",
    "        print(pairs_1)\n",
    "        \n",
    "        #list comprehension\n",
    "        pairs_2 = [[num1, num2] for num1 in range(0,2) for num2 in range(6,8)]\n",
    "        print(pairs_2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd478e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list comprehension: squares\n",
    "squares = [i ** 2 for i in range(0,10)]\n",
    "print(squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c37659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 5 x 5 matrix using a list of lists: matrix\n",
    "matrix = [[col for col in range(5)] for row in range(5)]\n",
    "\n",
    "# Print the matrix\n",
    "for row in matrix:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f864a1",
   "metadata": {},
   "source": [
    "#### Conditionals in comprehensions\n",
    "\n",
    "- example: \n",
    "        [output FOR iterator variable IN iterable IF predicate expression]\n",
    "\n",
    "Dictionary comprehensions, similar to list comprehensions\n",
    "- use curly braces instead of brackets and require colon to seperate key and value in output expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53b4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use member as the iterator variable in the list comprehension. \n",
    "#For the conditional, use len() to evaluate the iterator variable. \n",
    "#Note that you only want strings with 7 characters or more.\n",
    "\n",
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# Create list comprehension: new_fellowship\n",
    "new_fellowship = [member for member in fellowship if len(member) >= 7]\n",
    "\n",
    "# Print the new list\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56402a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the output expression, keep the string as-is \n",
    "# if the number of characters is >= 7, else replace it with an empty string \n",
    "\n",
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# Create list comprehension: new_fellowship\n",
    "new_fellowship = [member if len(member) >= 7 else '' for member in fellowship]\n",
    "\n",
    "# Print the new list\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0782ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dictionary Comprehensions\n",
    "\n",
    "# Create a dict comprehension where the key is a string in fellowship \n",
    "# and the value is the length of the string.\n",
    "# syntax <key> : <value> in the output expression part of the comprehension to create the members of the dictionary\n",
    "# Use member as the iterator variable.\n",
    "\n",
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# Create dict comprehension: new_fellowship\n",
    "new_fellowship = {member:len(member) for member in fellowship}\n",
    "\n",
    "# Print the new dictionary\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9181fec4",
   "metadata": {},
   "source": [
    "##### Intro to generator expressions\n",
    "\n",
    "- Replace the square brackets with round brackets to create a generator\n",
    "- like llst comprehension except list is not stored in memory\n",
    "- useful to prevent storing large comprehensions in memory, useful for generating elements of sequence as needed\n",
    "\n",
    "- can do comprehensions and conditionals the same as lists\n",
    "\n",
    "- generator functions produce generator objects when called\n",
    "    - use keyword YIELD rather than RETURN\n",
    "        def num_sequence(n):\n",
    "            \"\"\"Generate values from 0 to n\"\"\"\n",
    "            i = 0\n",
    "            while i < n:\n",
    "                yield i\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d5d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a generator object that will produce values from 0 to 30\n",
    "# Create generator object: result\n",
    "result = (num for num in range(31))\n",
    "\n",
    "# Print the first 5 values\n",
    "print(next(result))\n",
    "print(next(result))\n",
    "print(next(result))\n",
    "print(next(result))\n",
    "print(next(result))\n",
    "\n",
    "# Print the rest of the values\n",
    "for value in result:\n",
    "    print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff635ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a generator expression that will generate the lengths of each string in lannister.\n",
    "\n",
    "# Create a list of strings: lannister\n",
    "lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']\n",
    "\n",
    "# Create a generator object: lengths\n",
    "lengths = (len(person) for person in lannister)\n",
    "\n",
    "# Iterate over and print the values in lengths\n",
    "for value in lengths:\n",
    "    print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682094b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a generator function\n",
    "\n",
    "# Create a list of strings\n",
    "lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']\n",
    "\n",
    "# Define generator function get_lengths\n",
    "def get_lengths(input_list):\n",
    "    \"\"\"Generator function that yields the\n",
    "    length of the strings in input_list.\"\"\"\n",
    "\n",
    "    # Yield the length of a string\n",
    "    for person in input_list:\n",
    "        yield len(person)\n",
    "\n",
    "# Print the values generated by get_lengths()\n",
    "for value in get_lengths(lannister):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce733de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the column 'created_at' from df and assign the result to tweet_time\n",
    "#Create a list comprehension that extracts the time from each row in tweet_time. \n",
    "# Each row is a string that represents a timestamp, and you will access \n",
    "#the 12th to 19th characters in the string to extract the time.\n",
    "\n",
    "# Extract the created_at column from df: tweet_time\n",
    "tweet_time = df['created_at']\n",
    "\n",
    "# Extract the clock time: tweet_clock_time\n",
    "tweet_clock_time = [entry[11:19] for entry in tweet_time]\n",
    "\n",
    "# Print the extracted times\n",
    "print(tweet_clock_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6586a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list comprehension that extracts the time from each row in tweet_time. \n",
    "#Each row is a string that represents a timestamp, and you will access the 12th to 19th characters in the string to extract the time. Use entry as the iterator variable and assign the result to tweet_clock_time. \n",
    "#Additionally, add a conditional expression that checks whether entry[17:19] is equal to '19'.\n",
    "\n",
    "# Extract the created_at column from df: tweet_time\n",
    "tweet_time = df['created_at']\n",
    "\n",
    "# Extract the clock time: tweet_clock_time\n",
    "tweet_clock_time = [entry[11:19] for entry in tweet_time if entry[17:19] == '19']\n",
    "\n",
    "# Print the extracted times\n",
    "print(tweet_clock_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9dd514",
   "metadata": {},
   "source": [
    "### CHAPTER 3 - CASE STUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip lists: zipped_lists\n",
    "zipped_lists = zip(feature_names, row_vals)\n",
    "\n",
    "# Create a dictionary: rs_dict\n",
    "rs_dict = dict(zipped_lists)\n",
    "\n",
    "# Print the dictionary\n",
    "print(rs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f415f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing a function for the process\n",
    "\n",
    "# Define lists2dict()\n",
    "def lists2dict(list1, list2):\n",
    "    \"\"\"Return a dictionary where list1 provides\n",
    "    the keys and list2 provides the values.\"\"\"\n",
    "\n",
    "    # Zip lists: zipped_lists\n",
    "    zipped_lists = zip(list1, list2)\n",
    "\n",
    "    # Create a dictionary: rs_dict\n",
    "    rs_dict = dict(zipped_lists)\n",
    "\n",
    "    # Return the dictionary\n",
    "    return rs_dict\n",
    "\n",
    "# Call lists2dict: rs_fxn\n",
    "rs_fxn = lists2dict(feature_names, row_vals)\n",
    "\n",
    "# Print rs_fxn\n",
    "print(rs_fxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d17b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using list comprehension\n",
    "## use a list comprehension to generate a list of dicts, \n",
    "## where the keys are the header names and the values are the row entries.\n",
    "\n",
    "# Print the first two lists in row_lists\n",
    "print(row_lists[0])\n",
    "print(row_lists[1])\n",
    "\n",
    "# Turn list of lists into list of dicts: list_of_dicts\n",
    "list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_lists]\n",
    "\n",
    "# Print the first two dictionaries in list_of_dicts\n",
    "print(list_of_dicts[0])\n",
    "print(list_of_dicts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Turning dictionary into a Dataframe\n",
    "\n",
    "# Import the pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Turn list of lists into list of dicts: list_of_dicts\n",
    "list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_lists]\n",
    "\n",
    "# Turn list of dicts into a DataFrame: df\n",
    "df = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f9be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing data in chunks\n",
    "\n",
    "#open a connection to this file using a context manager\n",
    "# Open a connection to the file\n",
    "with open('world_dev_ind.csv') as file:\n",
    "\n",
    "    # Skip the column names\n",
    "    file.readline()\n",
    "\n",
    "    # Initialize an empty dictionary: counts_dict\n",
    "    counts_dict = {}\n",
    "\n",
    "    # Process only the first 1000 rows\n",
    "    for j in range(0,1000):\n",
    "\n",
    "        # Split the current line into a list: line\n",
    "        line = file.readline().split(',')\n",
    "\n",
    "        # Get the value for the first column: first_col\n",
    "        first_col = line[0]\n",
    "\n",
    "        # If the column value is in the dict, increment its value\n",
    "        if first_col in counts_dict.keys():\n",
    "            counts_dict[first_col] += 1\n",
    "\n",
    "        # Else, add to the dict and set value to 1\n",
    "        else:\n",
    "            counts_dict[first_col] = 1\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c6ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing a generator to load data in chunks\n",
    "\n",
    "# Define read_large_file()\n",
    "def read_large_file(file_object):\n",
    "    \"\"\"A generator function to read a large file lazily.\"\"\"\n",
    "\n",
    "    # Loop indefinitely until the end of the file\n",
    "    while True:\n",
    "\n",
    "        # Read a line from the file: data\n",
    "        data = file_object.readline()\n",
    "\n",
    "        # Break if this is the end of the file\n",
    "        if not data:\n",
    "            break\n",
    "\n",
    "        # Yield the line of data\n",
    "        yield data\n",
    "        \n",
    "# Open a connection to the file\n",
    "with open('world_dev_ind.csv') as file:\n",
    "\n",
    "    # Create a generator object for the file: gen_file\n",
    "    gen_file = read_large_file(file)\n",
    "\n",
    "    # Print the first three lines of the file\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))\n",
    "    \n",
    "## Note that since a file object is already a generator, \n",
    "## you don't have to explicitly create a generator object with your read_large_file() function. \n",
    "## However, it is still good to practice how to create generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e3c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use generator to process large files\n",
    "\n",
    "# Initialize an empty dictionary: counts_dict\n",
    "counts_dict = {}\n",
    "\n",
    "# Open a connection to the file\n",
    "with open('world_dev_ind.csv') as file:\n",
    "\n",
    "    # Iterate over the generator from read_large_file()\n",
    "    for line in read_large_file(file):\n",
    "\n",
    "        row = line.split(',')\n",
    "        first_col = row[0]\n",
    "\n",
    "        if first_col in counts_dict.keys():\n",
    "            counts_dict[first_col] += 1\n",
    "        else:\n",
    "            counts_dict[first_col] = 1\n",
    "\n",
    "# Print            \n",
    "print(counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10b1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing an iterator to load data in chunks\n",
    "## read a file in small DataFrame chunks with read_csv()\n",
    "\n",
    "# Import the pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize reader object: df_reader\n",
    "df_reader = pd.read_csv(\"ind_pop.csv\", chunksize=10)\n",
    "\n",
    "# Print two chunks\n",
    "print(next(df_reader))\n",
    "print(next(df_reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3942ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing an iterator to load data in chunks\n",
    "## read in a file using a bigger DataFrame chunk size and \n",
    "## then process the data from the first chunk\n",
    "## To process the data, you will create another DF composed of only the rows from a specific country. \n",
    "## zip together two of the columns from the new DataFrame, 'Total Population' and 'Urban population (% of total)'\n",
    "## Finally, you will create a list of tuples from the zip object, \n",
    "## where each tuple is composed of a value from each of the two columns mentioned.\n",
    "\n",
    "# Initialize reader object: urb_pop_reader\n",
    "urb_pop_reader = pd.read_csv('ind_pop_data.csv', chunksize=1000)\n",
    "\n",
    "# Get the first DataFrame chunk: df_urb_pop\n",
    "df_urb_pop = next(urb_pop_reader)\n",
    "\n",
    "# Check out the head of the DataFrame\n",
    "print(df_urb_pop.head())\n",
    "\n",
    "# Check out specific country: df_pop_ceb\n",
    "df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
    "\n",
    "# Zip DataFrame columns of interest: pops\n",
    "pops = zip(df_pop_ceb['Total Population'], df_pop_ceb['Urban population (% of total)'])\n",
    "\n",
    "# Turn zip object into list: pops_list\n",
    "pops_list = list(pops)\n",
    "\n",
    "# Print pops_list\n",
    "print(pops_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "##write list comprehension to create the values for a new column 'Total Urban Population' \n",
    "## from the list of tuples that you generated earlier. \n",
    "## Recall from the previous exercise that the first and second elements of each tuple consist of\n",
    "## values from the columns 'Total Population' and 'Urban population (% of total)'. \n",
    "## The values in this new column 'Total Urban Population', therefore, \n",
    "##are the product of the first and second element in each tuple. \n",
    "##Furthermore, because the 2nd element is a percentage, \n",
    "##you need to divide the entire result by 100, OR multiply it by 0.01\n",
    "\n",
    "# Code from previous exercise\n",
    "urb_pop_reader = pd.read_csv('ind_pop_data.csv', chunksize=1000)\n",
    "df_urb_pop = next(urb_pop_reader)\n",
    "df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
    "pops = zip(df_pop_ceb['Total Population'], \n",
    "           df_pop_ceb['Urban population (% of total)'])\n",
    "pops_list = list(pops)\n",
    "\n",
    "# Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
    "df_pop_ceb['Total Urban Population'] = [int(value[0]*value[1]*0.01) for value in pops_list]\n",
    "\n",
    "# Plot urban population data\n",
    "df_pop_ceb.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae6b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In the previous exercises, you've only processed the data from the first chunk. \n",
    "## This time, you will aggregate the results over all the DataFrame chunks in the dataset. \n",
    "## This basically means you will be processing the entire dataset now. \n",
    "\n",
    "# Initialize reader object: urb_pop_reader\n",
    "urb_pop_reader = pd.read_csv('ind_pop_data.csv', chunksize=1000)\n",
    "\n",
    "# Initialize empty DataFrame: data\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Iterate over each DataFrame chunk\n",
    "for df_urb_pop in urb_pop_reader:\n",
    "\n",
    "    # Check out specific country: df_pop_ceb\n",
    "    df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
    "\n",
    "    # Zip DataFrame columns of interest: pops\n",
    "    pops = zip(df_pop_ceb['Total Population'],\n",
    "                df_pop_ceb['Urban population (% of total)'])\n",
    "\n",
    "    # Turn zip object into list: pops_list\n",
    "    pops_list = list(pops)\n",
    "\n",
    "    # Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
    "    df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
    "    \n",
    "    # Append DataFrame chunk to data: data\n",
    "    data = data.append(df_pop_ceb)\n",
    "\n",
    "# Plot urban population data\n",
    "data.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b5236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## put all the code for processing the data into a single function\n",
    "\n",
    "# Define plot_pop()\n",
    "def plot_pop(filename, country_code):\n",
    "\n",
    "    # Initialize reader object: urb_pop_reader\n",
    "    urb_pop_reader = pd.read_csv(filename, chunksize=1000)\n",
    "\n",
    "    # Initialize empty DataFrame: data\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over each DataFrame chunk\n",
    "    for df_urb_pop in urb_pop_reader:\n",
    "        # Check out specific country: df_pop_ceb\n",
    "        df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == country_code]\n",
    "\n",
    "        # Zip DataFrame columns of interest: pops\n",
    "        pops = zip(df_pop_ceb['Total Population'],\n",
    "                    df_pop_ceb['Urban population (% of total)'])\n",
    "\n",
    "        # Turn zip object into list: pops_list\n",
    "        pops_list = list(pops)\n",
    "\n",
    "        # Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
    "        df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
    "    \n",
    "        # Append DataFrame chunk to data: data\n",
    "        data = data.append(df_pop_ceb)\n",
    "\n",
    "    # Plot urban population data\n",
    "    data.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
    "    plt.show()\n",
    "\n",
    "# Set the filename: fn\n",
    "fn = 'ind_pop_data.csv'\n",
    "\n",
    "# Call plot_pop for country code 'CEB'\n",
    "plot_pop('ind_pop_data.csv', 'CEB')\n",
    "\n",
    "# Call plot_pop for country code 'ARB'\n",
    "plot_pop('ind_pop_data.csv', 'ARB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
